{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bed5048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Attention Model Results ---\n",
      "Index 0 | Probs: [1.0, 0.0]\n",
      "Index 1 | Probs: [0.0, 1.0]\n",
      "Index 2 | Probs: [1.0, 0.0]\n",
      "Index 3 | Probs: [0.0, 1.0]\n",
      "Index 4 | Probs: [1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import math, random\n",
    "\n",
    "# --- 1. CONFIG ---\n",
    "vocab_size, embed_dim = 10, 4\n",
    "hidden_1, hidden_2 = 8, 4\n",
    "lr, l1_param, l2_param = 0.05, 0.001, 0.01\n",
    "margin, eps, mucoef, vecoef = 2.0, 1e-8, 0.9, 0.999\n",
    "dropout, t = 0.2, 0\n",
    "batch_size = 3  # <--- Added missing definition\n",
    "\n",
    "# Wider initialization to help gradients start moving\n",
    "embedding_table = [[random.uniform(-0.5, 0.5) for _ in range(embed_dim)] for _ in range(vocab_size)]\n",
    "Wq = [[random.uniform(-0.5, 0.5) for _ in range(embed_dim)] for _ in range(embed_dim)]\n",
    "Wk = [[random.uniform(-0.5, 0.5) for _ in range(embed_dim)] for _ in range(embed_dim)]\n",
    "Wv = [[random.uniform(-0.5, 0.5) for _ in range(embed_dim)] for _ in range(embed_dim)]\n",
    "neurons = [[random.uniform(-0.5, 0.5) for _ in range(embed_dim)] for _ in range(hidden_1)]\n",
    "layer_2 = [[random.uniform(-0.5, 0.5) for _ in range(hidden_1)] for _ in range(hidden_2)]\n",
    "weights = [[random.uniform(-0.5, 0.5) for _ in range(hidden_2)] for _ in range(2)]\n",
    "n_bias, l2_bias, w_bias = [0.1]*hidden_1, [0.1]*hidden_2, [0.1]*2 \n",
    "\n",
    "# Adam States\n",
    "def st(r, c=None): return [[0.0]*c for _ in range(r)] if c else [0.0]*r\n",
    "mu_q, ve_q = st(embed_dim, embed_dim), st(embed_dim, embed_dim)\n",
    "mu_k, ve_k = st(embed_dim, embed_dim), st(embed_dim, embed_dim)\n",
    "mu_v, ve_v = st(embed_dim, embed_dim), st(embed_dim, embed_dim)\n",
    "mu_e, ve_e = st(vocab_size, embed_dim), st(vocab_size, embed_dim)\n",
    "mu_n, ve_n = st(hidden_1, embed_dim), st(hidden_1, embed_dim)\n",
    "mu_l2, ve_l2 = st(hidden_2, hidden_1), st(hidden_2, hidden_1)\n",
    "mu_w, ve_w = st(2, hidden_2), st(2, hidden_2)\n",
    "mu_nb, ve_nb, mu_l2b, ve_l2b, mu_wb, ve_wb = st(hidden_1), st(hidden_1), st(hidden_2), st(hidden_2), st(2), st(2)\n",
    "\n",
    "dataset, target = [0, 1, 2, 3, 4], [[1, 0], [0, 1], [1, 0], [0, 1], [1, 0]]\n",
    "batch_count = 0\n",
    "\n",
    "# --- 2. TRAINING ---\n",
    "for epoch in range(500):\n",
    "    data_indices = list(range(len(dataset)))\n",
    "    random.shuffle(data_indices)\n",
    "\n",
    "    # Reset Batch Gradients\n",
    "    bq, bk, bv = st(embed_dim, embed_dim), st(embed_dim, embed_dim), st(embed_dim, embed_dim)\n",
    "    bw, bwb = st(2, hidden_2), st(2)\n",
    "    bl2, bl2b = st(hidden_2, hidden_1), st(hidden_2)\n",
    "    bn, bnb = st(hidden_1, embed_dim), st(hidden_1)\n",
    "    be = st(vocab_size, embed_dim)\n",
    "\n",
    "    for batch_idx, i in enumerate(data_indices):\n",
    "        batch_count += 1\n",
    "        emb_idx = dataset[i]\n",
    "        vecs = embedding_table[emb_idx]\n",
    "        \n",
    "        # Forward QKV\n",
    "        q_raw = [sum(vecs[k] * Wq[j][k] for k in range(embed_dim)) for j in range(embed_dim)]\n",
    "        k_raw = [sum(vecs[k] * Wk[j][k] for k in range(embed_dim)) for j in range(embed_dim)]\n",
    "        v_raw = [sum(vecs[k] * Wv[j][k] for k in range(embed_dim)) for j in range(embed_dim)]\n",
    "        score = sum(q_raw[m] * k_raw[m] for m in range(embed_dim)) / math.sqrt(embed_dim)\n",
    "        attn_out = [val * score for val in v_raw]\n",
    "\n",
    "        # Layer 1 + LayerNorm\n",
    "        n_pre = [sum(attn_out[k] * row[k] for k in range(embed_dim)) + n_bias[idx] for idx, row in enumerate(neurons)]\n",
    "        nm = sum(n_pre)/len(n_pre); nv = sum((x-nm)**2 for x in n_pre)/len(n_pre)\n",
    "        n_norm = [(x-nm)/math.sqrt(nv + 1e-6) for x in n_pre]\n",
    "        n_act = [max(0, x) for x in n_norm]\n",
    "        n_mask = [1 if random.random() > dropout else 0 for _ in range(hidden_1)]\n",
    "        n_logits = [(x * m)/(1-dropout) for x, m in zip(n_act, n_mask)]\n",
    "\n",
    "        # Layer 2\n",
    "        l2_pre = [sum(n_logits[k] * row[k] for k in range(hidden_1)) + l2_bias[idx] for idx, row in enumerate(layer_2)]\n",
    "        l2_act = [max(0, x) for x in l2_pre]\n",
    "        l2_mask = [1 if random.random() > dropout else 0 for _ in range(hidden_2)]\n",
    "        l2_logits = [(x * m)/(1-dropout) for x, m in zip(l2_act, l2_mask)]\n",
    "\n",
    "        # Output\n",
    "        logits = [sum(x * w for x, w in zip(l2_logits, row)) + w_bias[idx] for idx, row in enumerate(weights)]\n",
    "        t_l = list(logits); t_l[target[i].index(1)] /= margin\n",
    "        exps = [math.exp(x) for x in t_l]; sum_exps = sum(exps)\n",
    "        probs = [x / sum_exps for x in exps]\n",
    "\n",
    "        # --- BACKWARD ---\n",
    "        err_w = [probs[j] - target[i][j] for j in range(2)]\n",
    "        err_l2 = [sum(err_w[k] * weights[k][j] for k in range(2)) * (1 if l2_pre[j] > 0 else 0) * l2_mask[j] for j in range(hidden_2)]\n",
    "        err_n = [sum(err_l2[k] * layer_2[k][j] for k in range(hidden_2)) * (1 if n_pre[j] > 0 else 0) * n_mask[j] for j in range(hidden_1)]\n",
    "        \n",
    "        # Loss back to Attention\n",
    "        err_attn = [sum(err_n[j] * neurons[j][k] for j in range(hidden_1)) for k in range(embed_dim)]\n",
    "        err_v = [val * score for val in err_attn]\n",
    "        err_score = sum(err_attn[m] * v_raw[m] for m in range(embed_dim)) / math.sqrt(embed_dim)\n",
    "        err_q = [err_score * k_raw[m] for m in range(embed_dim)]\n",
    "        err_k = [err_score * q_raw[m] for m in range(embed_dim)]\n",
    "\n",
    "        # --- ACCUMULATE ---\n",
    "        for j in range(2):\n",
    "            for k in range(hidden_2): bw[j][k] += err_w[j] * l2_logits[k]\n",
    "            bwb[j] += err_w[j]\n",
    "        for j in range(hidden_2):\n",
    "            for k in range(hidden_1): bl2[j][k] += err_l2[j] * n_logits[k]\n",
    "            bl2b[j] += err_l2[j]\n",
    "        for j in range(hidden_1):\n",
    "            for k in range(embed_dim): bn[j][k] += err_n[j] * attn_out[k]\n",
    "            bnb[j] += err_n[j]\n",
    "        for j in range(embed_dim):\n",
    "            for k in range(embed_dim):\n",
    "                bq[j][k] += err_q[j] * vecs[k]\n",
    "                bk[j][k] += err_k[j] * vecs[k]\n",
    "                bv[j][k] += err_v[j] * vecs[k]\n",
    "        \n",
    "        err_e = [sum(err_q[j]*Wq[j][k] + err_k[j]*Wk[j][k] + err_v[j]*Wv[j][k] for j in range(embed_dim)) for k in range(embed_dim)]\n",
    "        for k in range(embed_dim): be[emb_idx][k] += err_e[k]\n",
    "\n",
    "        if batch_count == batch_size or (batch_idx + 1) == len(dataset):\n",
    "            t += 1\n",
    "            def up(p, b, m, v): # Standard Weight Update\n",
    "                for j in range(len(p)):\n",
    "                    for k in range(len(p[0])):\n",
    "                        g = b[j][k] / batch_count\n",
    "                        m[j][k] = mucoef * m[j][k] + (1-mucoef) * g\n",
    "                        v[j][k] = vecoef * v[j][k] + (1-vecoef) * (g**2)\n",
    "                        p[j][k] -= lr * (m[j][k]/(1-mucoef**t)) / (math.sqrt(v[j][k]/(1-vecoef**t)) + eps)\n",
    "\n",
    "            def up_b(p, b, m, v): # Bias Update\n",
    "                for j in range(len(p)):\n",
    "                    g = b[j] / batch_count\n",
    "                    m[j] = mucoef * m[j] + (1-mucoef) * g\n",
    "                    v[j] = vecoef * v[j] + (1-vecoef) * (g**2)\n",
    "                    p[j] -= lr * (m[j]/(1-mucoef**t)) / (math.sqrt(v[j]/(1-vecoef**t)) + eps)\n",
    "\n",
    "            up(Wq, bq, mu_q, ve_q); up(Wk, bk, mu_k, ve_k); up(Wv, bv, mu_v, ve_v)\n",
    "            up(neurons, bn, mu_n, ve_n); up(layer_2, bl2, mu_l2, ve_l2); up(weights, bw, mu_w, ve_w)\n",
    "            up_b(n_bias, bnb, mu_nb, ve_nb); up_b(l2_bias, bl2b, mu_l2b, ve_l2b); up_b(w_bias, bwb, mu_wb, ve_wb)\n",
    "            \n",
    "            # Embedding Update\n",
    "            for idx in range(vocab_size):\n",
    "                for k in range(embed_dim):\n",
    "                    g_e = be[idx][k] / batch_count\n",
    "                    mu_e[idx][k] = mucoef * mu_e[idx][k] + (1-mucoef) * g_e\n",
    "                    ve_e[idx][k] = vecoef * ve_e[idx][k] + (1-vecoef) * (g_e**2)\n",
    "                    embedding_table[idx][k] -= lr * (mu_e[idx][k]/(1-mucoef**t)) / (math.sqrt(ve_e[idx][k]/(1-vecoef**t)) + eps)\n",
    "\n",
    "            # Reset Gradients\n",
    "            bq, bk, bv = st(embed_dim, embed_dim), st(embed_dim, embed_dim), st(embed_dim, embed_dim)\n",
    "            bw, bwb = st(2, hidden_2), st(2); bl2, bl2b = st(hidden_2, hidden_1), st(hidden_2)\n",
    "            bn, bnb = st(hidden_1, embed_dim), st(hidden_1); be = st(vocab_size, embed_dim)\n",
    "            batch_count = 0\n",
    "\n",
    "# --- 3. TESTING ---\n",
    "print(\"\\n--- Final Attention Model Results ---\")\n",
    "for i in range(len(dataset)):\n",
    "    v_raw_test = [sum(embedding_table[dataset[i]][k] * Wv[j][k] for k in range(embed_dim)) for j in range(embed_dim)]\n",
    "    q_test = [sum(embedding_table[dataset[i]][k] * Wq[j][k] for k in range(embed_dim)) for j in range(embed_dim)]\n",
    "    k_test = [sum(embedding_table[dataset[i]][k] * Wk[j][k] for k in range(embed_dim)) for j in range(embed_dim)]\n",
    "    score_test = sum(q_test[m] * k_test[m] for m in range(embed_dim)) / math.sqrt(embed_dim)\n",
    "    attn_test = [val * score_test for val in v_raw_test]\n",
    "    \n",
    "    n_p = [sum(attn_test[k] * row[k] for k in range(embed_dim)) + n_bias[idx] for idx, row in enumerate(neurons)]\n",
    "    n_m = sum(n_p)/len(n_p); n_v = sum((x-n_m)**2 for x in n_p)/len(n_p)\n",
    "    n_n = [(x-n_m)/math.sqrt(n_v + 1e-6) for x in n_p]\n",
    "    n_a = [max(0, x) for x in n_n]\n",
    "    \n",
    "    l2_p = [sum(n_a[k] * row[k] for k in range(hidden_1)) + l2_bias[idx] for idx, row in enumerate(layer_2)]\n",
    "    l2_a = [max(0, x) for x in l2_p]\n",
    "    out = [sum(x * w for x, w in zip(l2_a, row)) + w_bias[idx] for idx, row in enumerate(weights)]\n",
    "    probs = [round(math.exp(x)/sum(math.exp(y) for y in out), 3) for x in out]\n",
    "    print(f\"Index {dataset[i]} | Probs: {probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8475967",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_games = [\n",
    "    [0.1, 0.8, 0.1],\n",
    "    [0.9, 0.9, 0.9], \n",
    "    [0.8, 0.2, 0.5],\n",
    "]\n",
    "results = [0, 0, 1]\n",
    "\n",
    "def knn_predict(new_data, dataset, targets, k=3):\n",
    "    distances = []\n",
    "    for i in range(len(dataset)):\n",
    "        dist = sum((new_data[j] - dataset[i][j])**2 for j in range(len(new_data)))**0.5\n",
    "        distances.append((dist, targets[i]))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    nearest = [d[1] for d in distances[:k]]\n",
    "    return \"Хит\" if max(set(nearest), key=nearest.count) == 0 else \"Провал\"\n",
    "\n",
    "test_game = [0.15, 0.85, 0.12]\n",
    "print(f\"Вердикт KNN: {knn_predict(test_game, old_games, results, k=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afff137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(game):\n",
    "    if game[1] > 0.8:\n",
    "        if game[0] < 0.3: return \"Инди-хит\"\n",
    "        else: return \"Блокбастер\"\n",
    "    else: return \"Провал\"\n",
    "\n",
    "new_game = [0.1, 0.9, 0.5]\n",
    "print(f\"Вердикт дерева: {tree_predict(new_game)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "dataset = [[0.1, 0.8, 0.1], [0.9, 0.9, 0.9], [0.8, 0.2, 0.5]]\n",
    "targets = [1, 1, -1] \n",
    "weights = [random.uniform(-0.1, 0.1) for _ in range(3)]\n",
    "bias = 0.0\n",
    "lr = 0.01 * 2\n",
    "C = 1.0\n",
    "epochs = 1000\n",
    "l1_param = 0.005\n",
    "l2_param = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, x in enumerate(dataset):\n",
    "        condition = targets[i] * (sum(x[j] * weights[j] for j in range(3)) + bias)\n",
    "        if condition >= 1:\n",
    "            for j in range(3):\n",
    "                weights[j] -= lr * (l2_param * weights[j] + l1_param * (1 if weights[j] > 0 else -1))\n",
    "        else:\n",
    "            for j in range(3):\n",
    "                weights[j] -= lr * (l2_param * weights[j] - C * x[j] * targets[i])\n",
    "            bias += lr * C * targets[i]\n",
    "\n",
    "test_game = [0.15, 0.85, 0.12]\n",
    "result = sum(test_game[j] * weights[j] for j in range(3)) + bias\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "prob_hit = sigmoid(result)\n",
    "print(f\"SVM вердикт: {'Хит' if result > 0 else 'Провал'}\")\n",
    "print(f\"Счет (Score): {result:.2f}\")\n",
    "print(f\"Уверенность (Вероятность Хима): {prob_hit:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
