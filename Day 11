Goal: to continue linear

Insight: there's some kinda velocity - momentum in sqrt

Action: added velocity

import math
import random

dataset = [[0.1, 0.8, 1.0], [0.9, 0.2, 0.1], [0.2, 0.9, 0.7]]
target = [[1, 0], [0, 1], [1, 0]]

lr = 0.02
mu_coef = 0.9    
ve_coef = 0.999      
eps = 1e-8          
l1_param = 0.005
l2_param = 0.01
margin = 2.0

neurons = [[random.uniform(-0.1, 0.1) for _ in range(3)] for _ in range(4)]
n_bias = [0.0] * 4
mu_n = [[0.0] * 3 for _ in range(4)]
ve_n = [[0.0] * 3 for _ in range(4)] # Velocity для скрытого слоя

weights = [[random.uniform(-0.1, 0.1) for _ in range(4)] for _ in range(2)]
w_bias = [0.0] * 2
mu_w = [[0.0] * 4 for _ in range(2)]
ve_w = [[0.0] * 4 for _ in range(2)] # Velocity для выходного слоя

for epoch in range(500):
    for i in range(len(dataset)):
        x, t = dataset[i], target[i]

        n_logits = [max(0, sum(v * w for v, w in zip(x, row)) + b) for row, b in zip(neurons, n_bias)]
        logits = [sum(v * w for v, w in zip(n_logits, row)) + b for row, b in zip(weights, w_bias)]

        logits[t.index(1)] /= margin

        exps = [math.exp(l) for l in logits]
        probs = [e / sum(exps) for e in exps]

        w_loss = [probs[j] - t[j] for j in range(2)]
        for j in range(2):
            for k in range(4):
                grad = w_loss[j] * n_logits[k]
                reg = (l2_param * weights[j][k]) + (l1_param * (1 if weights[j][k] > 0 else -1))
                total_grad = grad + reg
                
                mu_w[j][k] = mu_coef * mu_w[j][k] + (1 - mu_coef) * total_grad
                ve_w[j][k] = ve_coef * ve_w[j][k] + (1 - ve_coef) * (total_grad**2)
                
                weights[j][k] -= lr * mu_w[j][k] / (math.sqrt(ve_w[j][k]) + eps)
            w_bias[j] -= lr * w_loss[j]

        for j in range(4):
            error = sum(w_loss[k] * weights[k][j] for k in range(2))
            n_loss_j = error * (1 if n_logits[j] > 0 else 0)
            
            for k in range(3):
                grad = n_loss_j * x[k]
                mu_n[j][k] = mu_coef * mu_n[j][k] + (1 - mu_coef) * grad
                ve_n[j][k] = ve_coef * ve_n[j][k] + (1 - ve_coef) * (grad**2)
                
                neurons[j][k] -= lr * mu_n[j][k] / (math.sqrt(ve_n[j][k]) + eps)
            n_bias[j] -= lr * n_loss_j

print("Обучение с Momentum и Velocity завершено!")
